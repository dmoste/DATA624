---
title: "DATA624 Project 1"
author: "Daniel Moscoe"
date: "6/24/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(fpp2)
library(readxl)
```

```{r}
xlsx_path <- "raw_data.xlsx"
raw <- readxl::read_xlsx(xlsx_path)
```

[This file examines variables S05Var03, S06Var05, and S06Var07.]

## Exploratory Visualization

This section contains initial visualizations of S05Var03, S06Var05, and S06Var07. These visualizations provide the basis for initial commentary and suggest a roadmap for the analysis that comprises the remainder of this file.

```{r}
raw %>%
  ggplot(aes(x = SeriesInd, y = S05Var03)) +
  geom_line() +
  ggtitle("S05Var03")

raw %>%
  ggplot(aes(x = SeriesInd, y = S06Var05)) +
  geom_line() +
  ggtitle("S06Var05")

raw %>%
  ggplot(aes(x = SeriesInd, y = S06Var07)) +
  geom_line() +
  ggtitle("S06Var07")
```

All three variables closely resemble a random walk. The variables from group S06 closely resemble each other. None of the variables exhibits obvious seasonality or cyclicity. None of the variables is stationary. The group S06 variables appear to trend upward after `SeriesInd` = 41250, but because the data are compressed toward the bottom of the grid due to a small number of extreme outliers, it's hard to be sure at this early stage. For all three variables, variability in the data does not appear to depend on the level of the data.

Examining the numeric data reveals gaps in the `SeriesInd` column. These gaps mostly occur at regular intervals, and could represent weekends and holidays in a calendar.

Do the gaps represent a pause in the process that generated this data? Or do the gaps indicate unknown values in the time series? If the average change in value across these gaps is larger than the typical difference between a value and its lag, then there's reason to think these gaps represent missing data. If the average change across these gaps is approximately equal to the typical change from one value to the next, then the gaps probably represent a pause in the data-generating process.

Computing the average squared difference across gaps for S06Var05:
```{r}
SeriesInd.ts <- ts(raw$SeriesInd)
gaps <- diff(SeriesInd.ts) > 1
gaps <- c(FALSE, gaps)
gaps.df <- data.frame("SeriesInd" = raw$SeriesInd, "AfterGap" = gaps)

gaps.df <- gaps.df %>%
  mutate("S06Var05" = raw$S06Var05, "S06Var05.diff" = raw$S06Var05 - lag(raw$S06Var05))

sqdiff_across_gaps_S06Var05 <- gaps.df %>%
  filter(AfterGap) %>%
  filter(S06Var05.diff > -50) %>%
  select(S06Var05.diff)

sqdiff_across_gaps_S06Var05 <- sqdiff_across_gaps_S06Var05^2
sqdiff_across_gaps_S06Var05 <-
  mean(sqdiff_across_gaps_S06Var05$S06Var05.diff)
```

Computing the average squared difference between successive entries for S06Var05:
```{r}
sqdiff_across_all <- gaps.df %>%
  filter(abs(S06Var05.diff) < 50) %>%
  select(S06Var05.diff)

sqdiff_across_all <- sqdiff_across_all^2
sqdiff_across_all <- mean(sqdiff_across_all$S06Var05.diff)
```

The mean square difference between values across gaps is 0.376, and the mean square difference between all successive values is 0.326. These values are close enough to suggest that missing values in the `SeriesInd` column represent a pause in the data-generating process, rather than missing data. As a result, we can treat this data as if all the measurements are consecutive, with no missingness.

While it's not known what process generated these data, the levels and behavior of the data are similar to those of stock prices. For the purpose of this report, I'll regard each value as a closing stock price of a different company, and I'll regard the time series values as counting days. Restarting the time series at Day = 0 and dropping outliers from the group S06 data gives us the following:

```{r}
RST.ts <- ts(raw$S05Var03)

UVW.ts <- raw %>%
  filter(S06Var05 < 100) %>%
  select(S06Var05) %>%
  ts()

XYZ.ts <- raw %>%
  filter(S06Var07 < 100) %>%
  select(S06Var07) %>%
  ts()

autoplot(RST.ts) +
  xlab("Day") +
  ylab("Closing Price (USD)") +
  ggtitle("Daily Closing Price of RST")

autoplot(UVW.ts) +
  xlab("Day") +
  ylab("Closing Price (USD)") +
  ggtitle("Daily Closing Price of UVW")

autoplot(XYZ.ts) +
  xlab("Day") +
  ylab("Closing Price (USD)") +
  ggtitle("Daily Closing Price of XYZ")
```

How similar are the time series representing UVW and XYZ?

```{r}
autoplot(UVW.ts-XYZ.ts) +
  xlab("Day") +
  ylab("Difference in price (USD)") +
  ggtitle("Daily difference in prices, UVW and XYZ")
```

Differences in price are white noise centered at zero. The range of these differences is small compared to the level of each variable. For this reason, I'll restrict the analysis to only UVW, and then apply the best model for UVW to XYZ as well.

## Simple forecasts

Because "a naive forecast is optimal when data follow a random walk" (HA 3.1), I compute some simple forecasts for each variable before performing more complex analysis. The performance of these simple models will provide a benchmark for performance of more sophisticated models. In the event of a tie, I'll favor these simpler models.

```{r}
RST_rwf <- rwf(RST.ts, h = 140)
UVW_rwf <- rwf(UVW.ts, h = 140)
RST_drwf <- rwf(RST.ts, h = 140, drift = TRUE)
UVW_drwf <- rwf(UVW.ts, h = 140, drift = TRUE)
RST_mean <- meanf(RST.ts, h = 140)
UVW_mean <- meanf(UVW.ts, h = 140)


autoplot(RST.ts) +
  autolayer(RST_rwf, series = "Naive", PI = FALSE) +
  autolayer(RST_drwf, series = "Drift", PI = FALSE) +
  autolayer(RST_mean, series = "Mean", PI = FALSE)

autoplot(UVW.ts) +
  autolayer(UVW_rwf, series = "Naive", PI = FALSE) +
  autolayer(UVW_drwf, series = "Drift", PI = FALSE) +
  autolayer(UVW_mean, series = "Mean", PI = FALSE)
```

Evaluating performance of simple models using RMSE:
```{r}
RST_rmse_rwf_nodrift <- tsCV(RST.ts, rwf, drift = FALSE, h = 1)
RST_rmse_rwf_nodrift <- sqrt(mean(RST_rmse_rwf_nodrift^2, na.rm = TRUE))

RST_rmse_rwf_drift <- tsCV(RST.ts, rwf, drift = TRUE, h = 1)
RST_rmse_rwf_drift <- sqrt(mean(RST_rmse_rwf_drift^2, na.rm = TRUE))

RST_rmse_meanf <- tsCV(RST.ts, meanf, h = 1)
RST_rmse_meanf <- sqrt(mean(RST_rmse_meanf^2, na.rm = TRUE))

UVW_rmse_rwf_nodrift <- tsCV(UVW.ts, rwf, drift = FALSE, h = 1)
UVW_rmse_rwf_nodrift <- sqrt(mean(UVW_rmse_rwf_nodrift^2, na.rm = TRUE))

UVW_rmse_rwf_drift <- tsCV(UVW.ts, rwf, drift = TRUE, h = 1)
UVW_rmse_rwf_drift <- sqrt(mean(UVW_rmse_rwf_drift^2, na.rm = TRUE))

UVW_rmse_meanf <- tsCV(UVW.ts, meanf, h = 1)
UVW_rmse_meanf <- sqrt(mean(UVW_rmse_meanf^2, na.rm = TRUE))
```

For both RST and UVW, the best-performing model is the random walk forecast with no drift. For RST, RMSE = 0.9037. For UVW, RMSE = 0.5712.

## Exponential smoothing

Below, I fit a simple exponential smoothing method. Because the best-performing simple model did not include trend, I won't examine trended methods, like `holt()`.

```{r}
RST_ses <- ses(RST.ts, h = 140)
summary(RST_ses)
```

The optimized simple exponential smoothing method computed $\alpha = 0.9999$, making this method almost indistinguishable from the random-walk forecast. It offers a tiny improvement in performance when measured as RMSE, but this improvement is not sufficient to justify a more complex model.

```{r}
UVW_ses <- ses(UVW.ts, h = 140)
summary(UVW_ses)
```

For UVW, $\alpha = 0.8676$, indicating that optimal simple exponential smoothing does take some account of values earlier than lag-1. Similar to SES's performance with RST, SES offers only a very small performance gain over the random-walk forecast. This small gain is not sufficient to justify a more complex model.




















































