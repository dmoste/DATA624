---
title: "draft_proj1_210622"
author: "Daniel Moscoe"
date: "6/22/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(fpp2)
library(readxl)
```

```{r}
xlsx_path <- "raw_data.xlsx"
raw <- readxl::read_xlsx(xlsx_path)
summary(raw)
```

```{r}

raw %>%
#  filter(S06Var07 < 50) %>%
  ggplot(aes(x = SeriesInd, y = S06Var05)) +
    geom_line()
```

```{r}
ggplot(data = raw, aes(x = SeriesInd, y = S06Var07)) +
  geom_line()
```

```{r}
ggplot(data = as.data.frame(tmpdiffs), aes(x = seq(1:length(tmpdiffs)), y = tmpdiffs)) +
  geom_point()
```

S06Var05 and S06Var07 are very closely related. It looks like their non-lagged differences are mean 0, normally distributed, constant variance. Whatever model works for S06Var05 should also be applied to S06Var07.

Initial thoughts:
- Ignore the extreme outliers.
- Looks like a random walk with drift.
- Is there seasonality?

```{r}
S06Var05.ts <- ts(raw$S03Var05)
autoplot(S06Var05.ts)
```

Huh. Making it a ts just drops the outlier.

Trend
Cyclicity
Seasonality
Residual

Does converting this to a ts object ignore missing values? Are the missing values meaningful? If the variability of the values on either side of the missing regions is equal to the average variability, then the time series is stopped for those times, and you can drop the missing values. If the variability is greater, then the data is actually missing.

```{r}
autoplot(diff(S06Var05.ts))
```

Except for extreme outliers, the differences are mean 0 and it looks like their variability is related to the level of the ts.

So here's my plan right now:

*Check whether missingness is meaningful by comparing variability around missing periods with average variability.

*Check whether this fits a decomposition model and run it. What kind of decomposition will you choose? Produce forecasts.

*Then do an ARIMA model with first differences. Produce forecasts.

*Decide on one model.

### Check whether missingness is meaningful

```{r}
SeriesInd.ts <- ts(raw$SeriesInd)
gaps <- diff(SeriesInd.ts) > 1
gaps <- c(FALSE, gaps)
tmp <- as.vector(diff(SeriesInd.ts))
filter(tmp > 1) %>%
  
```

I want to get a list of data that occurs only directly before or after a gap. So first I need to identify where the gaps are. This is `gaps`. However, gaps is not matched with SeriesInd. So I need to get them together in the same data frame.

```{r}
gaps.df <- data.frame("SeriesInd" = raw$SeriesInd, "AfterGap" = gaps)
head(gaps.df)
```

Great. Now I have SeriesInd labeled with whether a row follows a gap. So I need to take all the values matching AfterGap, along with their lags, and compare the variance.

Just take the differences at AfterGap == True.

```{r}
gaps.df <- gaps.df %>%
  mutate("S06Var05" = raw$S06Var05, "S06Var07" = raw$S06Var07, "S06Var05.diff" = raw$S06Var05 - lag(raw$S06Var05), "S06Var07.diff" = raw$S06Var07 - lag(raw$S06Var07))
```

Variance across gaps:
```{r}
variance_across_gaps_S06Var05 <- gaps.df %>%
  filter(AfterGap) %>%
  filter(S06Var05.diff > -50) %>%
  select(S06Var05.diff) %>%
  var(na.rm = TRUE)

variance_across_gaps_S06Var07 <- gaps.df %>%
  filter(AfterGap) %>%
  filter(S06Var07.diff > -50) %>%
  select(S06Var07.diff) %>%
  var(na.rm = TRUE)
```

Compare to variance of all diffs:
```{r}
variance_S06Var05 <- gaps.df %>%
#  filter(AfterGap) %>%
  filter(abs(S06Var05.diff) < 50) %>%
  select(S06Var05.diff) %>%
  var(na.rm = TRUE)

variance_S06Var07 <- gaps.df %>%
#  filter(AfterGap) %>%
  filter(abs(S06Var07.diff) < 50) %>%
  select(S06Var07.diff) %>%
  var(na.rm = TRUE)
```

Barring outliers, the variances of diffs across gaps are almost equal to the variances of all diffs. So I would say that the gaps don't matter, and we can treat each variable like a time series with no missingness except for cells that are marked NA.

So now I'm going to examine S06Var05 and S06Var07 as time series objects.

```{r}
S06Var05.ts <- ts(raw$S06Var05)
S06Var07.ts <- ts(raw$S06Var07)
sum(is.na(S06Var05.ts))
sum(is.na(S06Var07.ts))
```
They both still have 145 missing values. Are these because of the gaps in SeriesInd?

```{r}
sum(gaps.df$AfterGap)
```

No, there were 379 gaps.

I'm going to try just removing the NAs.

Drop all NAs:
```{r}
S06Var05.ts <- raw %>%
  select(S06Var05) %>%
  filter(S06Var05 < 100) %>%
  drop_na() %>%
  ts()

S06Var07.ts <- raw %>%
  select(S06Var07) %>%
  filter(S06Var07 < 100) %>%
  drop_na() %>%
  ts()
```

I don't know if I treated the NAs exactly the right way... maybe better would have been to smoothly impute over them. But for now I'm just going to move on with my model. If I want to rerun the model later with the NAs imputed, that should be doable.

*Check whether this fits a decomposition model and run it. What kind of decomposition will you choose? Produce forecasts.

```{r}
autoplot(S06Var05.ts)
```


As it stands, S06Var05.ts has a frequency of 1. I have a hunch this data is prices for 
stocks not traded on weekends/holidays. So I will set the frequency to 52 to enable a seasonal 
decomposition, just to see what happens.
```{r}
ts(S06Var05.ts, frequency = 30) %>% decompose(type = 'additive') %>%
  autoplot() + xlab('Time') +
  ggtitle('Classical multiplicative decomp S06Var05')
```

A classical decomposition doesn't seem like a good model. The seasonal component is very small relative to the trend component and the level of the data. Varying the frequency of the time series didn't change this. Let's turn to exponential smoothing / methods based on exponential smoothing. The tiny seasonal component isn't going to change with some other decomposition method, even though other methods have other advantages.

